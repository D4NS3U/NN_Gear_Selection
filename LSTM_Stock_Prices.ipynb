{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Stock_Prices.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiJaHH31mhg1d2I1iFBZF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyingHirsch96/NN_Gear_Selection/blob/master/LSTM_Stock_Prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-6FGPRu5sB3",
        "colab_type": "text"
      },
      "source": [
        "#Using a Keras LSTM Model to predict stock prices\n",
        "Based on: https://github.com/mwitiderrick/stockprice.git\n",
        "This notebook helps me to better understand LSTMs. All credit on the overal design and data goes to Derrick Mwitid.\n",
        "\n",
        "This LSTM aims to \"predict\" stock prices based on past price movements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISpfZ-dF77R1",
        "colab_type": "text"
      },
      "source": [
        "##Loading the dataset\n",
        "First mandatory packages are imported. The url with the raw data (hosted by Derrick Mwiti) is 'saved' in the url-variable. Then the datasetTrain is generated by reading the csv-file through the pd.read command. The trainingSet-variable only contains the open and high colummns of the csv-file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCkSKyH85rSq",
        "colab_type": "code",
        "outputId": "22a2fea4-f10b-4204-a606-5d71b5188806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'\n",
        "\n",
        "datasetTrain = pd.read_csv(url)\n",
        "trainingSet = datasetTrain.iloc[:, 1:2].values\n",
        "\n",
        "datasetTrain.head()\n",
        "testVariable = []\n",
        "testVariable.append(trainingSet[0, 0])\n",
        "testVariable = np.array(testVariable)\n",
        "print(testVariable)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[234.05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Vplg3n8wAm",
        "colab_type": "text"
      },
      "source": [
        "##Feature scaling\n",
        "Mwitid states, that scaling the data will influence the performance of the LSTM. The MinMaxScaler from Scikit-Learns can normalize the values to numbers between zero and one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbL2jX6K9ebj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "trainingSetScaled = sc.fit_transform(trainingSet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxBdbP1u943L",
        "colab_type": "text"
      },
      "source": [
        "##Creating data with timestemps\n",
        "LSTMS expect data to be in a array. Lipton et al. give in 'A Critical Review of Recurrent Neural Networks for Sequence Learning' a nice summarization for the expected inputs and outputs for a recurrent neural network resp. a LSTM. To change the input data in a 3D array numpy is used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9kN3wSh-u-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xTrain = []\n",
        "yTrain = []\n",
        "for i in range (60, 2035):\n",
        "  xTrain.append(trainingSetScaled[i-60:i, 0])\n",
        "  yTrain.append(trainingSetScaled[i, 0])\n",
        "xTrain, yTrain = np.array(xTrain), np.array(yTrain)\n",
        "\n",
        "xTrain = np.reshape(xTrain, (xTrain.shape[0], xTrain.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2gkWD26Btve",
        "colab_type": "text"
      },
      "source": [
        "###Some prints for data evaluation an better understanding\n",
        "xTrain is a 3D array (thanks to the np.reshape) with 1975 vectors each consisting of 60 timesteps. The overal size of the array is therfore 60*1975=118500. yTrain is a 1D array consisting of 1975 different values.\n",
        "\n",
        "Therfore a sequence of 60 timesteps from xTrain is given as an input for the LSTM and the corresponding value of yTrain is given as the desired output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCduZTFB3Uh",
        "colab_type": "code",
        "outputId": "e03ff592-7f30-47cc-a399-b03872ca3f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"xTrain:\", xTrain)\n",
        "print(\"xTrain ndim:\", xTrain.ndim)\n",
        "print(\"xTrain shape:\", xTrain.shape)\n",
        "print(\"xTrain size:\", xTrain.size)\n",
        "print(\"xTrain[1] size:\", xTrain[1].size)\n",
        "print(\"xTrain[2] size:\", xTrain[2].size)\n",
        "print(\"yTrain:\", yTrain)\n",
        "print(\"yTrain ndim:\", yTrain.ndim)\n",
        "print(\"yTrain size:\", yTrain.size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xTrain: [[[0.6202352 ]\n",
            "  [0.62226277]\n",
            "  [0.64436334]\n",
            "  ...\n",
            "  [0.79622871]\n",
            "  [0.81062449]\n",
            "  [0.74371452]]\n",
            "\n",
            " [[0.62226277]\n",
            "  [0.64436334]\n",
            "  [0.61719384]\n",
            "  ...\n",
            "  [0.81062449]\n",
            "  [0.74371452]\n",
            "  [0.77007299]]\n",
            "\n",
            " [[0.64436334]\n",
            "  [0.61719384]\n",
            "  [0.61820762]\n",
            "  ...\n",
            "  [0.74371452]\n",
            "  [0.77007299]\n",
            "  [0.73641525]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.19870235]\n",
            "  [0.21796431]\n",
            "  [0.21553122]\n",
            "  ...\n",
            "  [0.14963504]\n",
            "  [0.14801298]\n",
            "  [0.15815085]]\n",
            "\n",
            " [[0.21796431]\n",
            "  [0.21553122]\n",
            "  [0.20600162]\n",
            "  ...\n",
            "  [0.14801298]\n",
            "  [0.15815085]\n",
            "  [0.16504461]]\n",
            "\n",
            " [[0.21553122]\n",
            "  [0.20600162]\n",
            "  [0.21654501]\n",
            "  ...\n",
            "  [0.15815085]\n",
            "  [0.16504461]\n",
            "  [0.15896188]]]\n",
            "xTrain ndim: 3\n",
            "xTrain shape: (1975, 60, 1)\n",
            "xTrain size: 118500\n",
            "xTrain[1] size: 60\n",
            "xTrain[2] size: 60\n",
            "yTrain: [0.77007299 0.73641525 0.73763179 ... 0.16504461 0.15896188 0.16626115]\n",
            "yTrain ndim: 1\n",
            "yTrain size: 1975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uZHOXT0EAab",
        "colab_type": "text"
      },
      "source": [
        "##Building the LSTM\n",
        "\n",
        "To build the LSTM a few modules from Keras are necessary.\n",
        "\n",
        "\n",
        "1.   Sequential is for initalizing the neural network.\n",
        "2.   Dense for adding a densely connected neural network layer.\n",
        "3.   LSTM for adding the LSTM layer(s).\n",
        "4.   Dropout for adding dropout layers that prevent overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGzUJEcLFaev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e92ef45-b9ee-46f0-bd50-cc44986b3b4a"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYrzNqJtFqIW",
        "colab_type": "text"
      },
      "source": [
        "First, the model *stockPricePredictor* is initialized. \n",
        "\n",
        "After this, four LSTM layers are added to the model. Each of the LSTM layer consist of 50 units, which means, that the output space of the layer will be 50. The statement return_sequences of the LSTM-layer decides, whether the output of the LSTM is the last output, or the full sequence. The latter is the case, if the statement is true. The statement input_shape 'tells' the LSTM-layer the shape/size of the input sequence.\n",
        "\n",
        "Between every LSTM-layer is a dropout. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting, as stated in the Keras documentation. A dropout rate of 0.2 means that 20% of the output is set to zero.\n",
        "\n",
        "After the LSTM-layers is a dense layer. A dense layer is a regular layer of a neural network with the special feature of having each neuron in the dense layer connected to each neuron of the previous layer. Dense layers a typical classifiation layers. Two important arguments of the dense layer are the number of units and the activation function. The number of units are set to one for this example, mostly because there is one output wanted for the whole sequence, which is the last open value of the stock in the input sequence. Because of the not further specified activation function, a linear activation y(x)=x is used as the activation of the neurons in the layer.\n",
        "\n",
        "The dense layer is the last layer of the neural network. It is then compiled, which means, that it is configured for training. Here get arguments like the used optimizer or the loss function set.\n",
        "\n",
        "After configuring the net for training, it is trained with the fit-command. Here the arguments input (xTrain), output (yTrain), epochs (100) and the batch_size (32) are set. That means that as input xTrain is used. For every Epochs, 32 sequences of xTrain are used, which should mean, that some sequences get trained double, because 32*100>1975.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhC_G0Pgv34M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df8a2c15-c663-409f-e6c6-9585fca3ec64"
      },
      "source": [
        "stockPricePredictor = Sequential()\n",
        "\n",
        "stockPricePredictor.add(LSTM(units=50, return_sequences=True, input_shape = (xTrain.shape[1], 1)))\n",
        "stockPricePredictor.add(Dropout(0.2))\n",
        "\n",
        "stockPricePredictor.add(LSTM(units=50, return_sequences=True))\n",
        "stockPricePredictor.add(Dropout(0.2))\n",
        "\n",
        "stockPricePredictor.add(LSTM(units=50, return_sequences=True))\n",
        "stockPricePredictor.add(Dropout(0.2))\n",
        "\n",
        "stockPricePredictor.add(LSTM(units=50))\n",
        "stockPricePredictor.add(Dropout(0.2))\n",
        "\n",
        "stockPricePredictor.add(Dense(units=1))\n",
        "\n",
        "stockPricePredictor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "stockPricePredictor.fit(xTrain, yTrain, epochs=100, batch_size=32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1975/1975 [==============================] - 10s 5ms/step - loss: 0.0086\n",
            "Epoch 2/100\n",
            "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0029\n",
            "Epoch 3/100\n",
            "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0032\n",
            "Epoch 4/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0025\n",
            "Epoch 5/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0027\n",
            "Epoch 6/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0023\n",
            "Epoch 7/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0020\n",
            "Epoch 8/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0018\n",
            "Epoch 9/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0019\n",
            "Epoch 10/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0020\n",
            "Epoch 11/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0019\n",
            "Epoch 12/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0018\n",
            "Epoch 13/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0017\n",
            "Epoch 14/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0016\n",
            "Epoch 15/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0017\n",
            "Epoch 16/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0014\n",
            "Epoch 17/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0014\n",
            "Epoch 18/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0015\n",
            "Epoch 19/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0014\n",
            "Epoch 20/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0016\n",
            "Epoch 21/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0016\n",
            "Epoch 22/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0014\n",
            "Epoch 23/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0016\n",
            "Epoch 24/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0012\n",
            "Epoch 25/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0013\n",
            "Epoch 26/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0013\n",
            "Epoch 27/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 0.0011\n",
            "Epoch 28/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0012\n",
            "Epoch 29/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0014\n",
            "Epoch 30/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0010\n",
            "Epoch 31/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0010\n",
            "Epoch 32/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.4723e-04\n",
            "Epoch 33/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.3305e-04\n",
            "Epoch 34/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0010\n",
            "Epoch 35/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 0.0011\n",
            "Epoch 36/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 9.0477e-04\n",
            "Epoch 37/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0011\n",
            "Epoch 38/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 9.4144e-04\n",
            "Epoch 39/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.9806e-04\n",
            "Epoch 40/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 9.2013e-04\n",
            "Epoch 41/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.9303e-04\n",
            "Epoch 42/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.8718e-04\n",
            "Epoch 43/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.9779e-04\n",
            "Epoch 44/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.1082e-04\n",
            "Epoch 45/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 8.7572e-04\n",
            "Epoch 46/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 8.9526e-04\n",
            "Epoch 47/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.9245e-04\n",
            "Epoch 48/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.7497e-04\n",
            "Epoch 49/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.5356e-04\n",
            "Epoch 50/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 9.2030e-04\n",
            "Epoch 51/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.8581e-04\n",
            "Epoch 52/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.8739e-04\n",
            "Epoch 53/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.3688e-04\n",
            "Epoch 54/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.3446e-04\n",
            "Epoch 55/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.8421e-04\n",
            "Epoch 56/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.7133e-04\n",
            "Epoch 57/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.3307e-04\n",
            "Epoch 58/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.1082e-04\n",
            "Epoch 59/100\n",
            "1975/1975 [==============================] - 13s 7ms/step - loss: 6.9953e-04\n",
            "Epoch 60/100\n",
            "1975/1975 [==============================] - 10s 5ms/step - loss: 8.5611e-04\n",
            "Epoch 61/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.3513e-04\n",
            "Epoch 62/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.7900e-04\n",
            "Epoch 63/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.9823e-04\n",
            "Epoch 64/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.8508e-04\n",
            "Epoch 65/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 8.8780e-04\n",
            "Epoch 66/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.8897e-04\n",
            "Epoch 67/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.8530e-04\n",
            "Epoch 68/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.4983e-04\n",
            "Epoch 69/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.1413e-04\n",
            "Epoch 70/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.6426e-04\n",
            "Epoch 71/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.6679e-04\n",
            "Epoch 72/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.3736e-04\n",
            "Epoch 73/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 8.1412e-04\n",
            "Epoch 74/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.2283e-04\n",
            "Epoch 75/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.1302e-04\n",
            "Epoch 76/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.5754e-04\n",
            "Epoch 77/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.1391e-04\n",
            "Epoch 78/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.2208e-04\n",
            "Epoch 79/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.1385e-04\n",
            "Epoch 80/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 7.6200e-04\n",
            "Epoch 81/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.3794e-04\n",
            "Epoch 82/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.8280e-04\n",
            "Epoch 83/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.5652e-04\n",
            "Epoch 84/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.0070e-04\n",
            "Epoch 85/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.5743e-04\n",
            "Epoch 86/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 7.7375e-04\n",
            "Epoch 87/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.3990e-04\n",
            "Epoch 88/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.6767e-04\n",
            "Epoch 89/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.6707e-04\n",
            "Epoch 90/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.5887e-04\n",
            "Epoch 91/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.4267e-04\n",
            "Epoch 92/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.9796e-04\n",
            "Epoch 93/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 5.6922e-04\n",
            "Epoch 94/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.6305e-04\n",
            "Epoch 95/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.2356e-04\n",
            "Epoch 96/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 5.1634e-04\n",
            "Epoch 97/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 5.5419e-04\n",
            "Epoch 98/100\n",
            "1975/1975 [==============================] - 9s 5ms/step - loss: 6.3358e-04\n",
            "Epoch 99/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.3158e-04\n",
            "Epoch 100/100\n",
            "1975/1975 [==============================] - 9s 4ms/step - loss: 6.8430e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff877a23710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYw9I4as2kKc",
        "colab_type": "text"
      },
      "source": [
        "###Conlusion of training\n",
        "\n",
        "As can be seen, the loss of the neural network gradualy decreased over time, meaning the performance resp. the accuracy of the net getting better. At epoch 38 the loss hits a plateu and fluctuates around 7.0e-04.\n",
        "\n",
        "##Predicting future stock using the test set\n",
        "The test set (hosted by Derrick Mwitid) get's imported just like the training set before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsGvezdl3T1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetTest = pd.read_csv('https://raw.githubusercontent.com/mwitiderrick/stockprice/master/tatatest.csv')\n",
        "realStockPrice = datasetTest.iloc[:, 1:2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq6Jkk_H3uot",
        "colab_type": "text"
      },
      "source": [
        "To predict future stock prices, there are the following preparatory things to load:\n",
        "\n",
        "\n",
        "1.   Merging training and test set on the 0 axis.\n",
        "2.   Set the time steps as 60 (as seen previously).\n",
        "3.   Normalize the input with MinMaxScaler.\n",
        "4.   Reshape the dataset to a 3D array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXoo6aoX4YRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetTotal = pd.concat((datasetTrain['Open'], datasetTest['Open']), axis = 0)\n",
        "inputs = datasetTotal[len(datasetTotal)-len(datasetTest)-60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "xTest = []\n",
        "for i in range(60, 76):\n",
        "  xTest.append(inputs[i-60:i, 0])\n",
        "xTest = np.array(xTest)\n",
        "xTest = np.reshape(xTest, (xTest.shape[0], xTest.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4Uy6hZv5qiB",
        "colab_type": "text"
      },
      "source": [
        "The prediction gets saved in the variable predictetdStockPrice. The prediction is made by using the predict method on the trained model. After that, the normalized predictions get inversed to a normal readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RmoHrfi6qhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedStockPrice = stockPricePredictor.predict(xTest)\n",
        "predictedStockPrice = sc.inverse_transform(predictedStockPrice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na644I5v69I4",
        "colab_type": "text"
      },
      "source": [
        "##Plotting the Results\n",
        "The results get plotted by using methods from Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eZ1d8f7SoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "edec65df-e08f-405e-a270-cfbc5f16e32d"
      },
      "source": [
        "plt.plot(realStockPrice, color = 'red', label = 'TATA Stock Price')\n",
        "plt.plot(predictedStockPrice, color = 'green', label = 'Predicted TATA Stock Price')\n",
        "plt.title('TATA Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('TATA Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ErirNSG74uo",
        "colab_type": "text"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "The LSTM RNN got trained to 'predict' a stock price, based on past stock prices. While the LSTM RNN definitely performs quite accurate, as seen in the graph above, the word 'prediction' should not be understoold literally. While there definetly is a prediction of values, all of them are past stock prices. The RNN can only predict the most recent stock price and is not able to realy compute a stock price in the actual future. This shows, that deep learning is not particularly used for 'predicting the future' but for pattern recognition. \n",
        "\n",
        "The slope at the beginning of the graph is most likely based on the inputs and outputs an how they are used to train the RNN. At first a sequence of 60 values get inputted one after another in the neural net. "
      ]
    }
  ]
}